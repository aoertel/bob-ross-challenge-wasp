{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Art Challenge - part 1 - The Bob Ross DCGAN\n",
    "AI Impact Lab, Ã–rebro University\n",
    "\n",
    "## This is a Jupyter Notebook\n",
    "\n",
    "A Jupyter Notebook is a great tool for creating interactive code tutorials. Runnable code is mixed with instructive text and explanations of what's going on. Put the mouse cursor in a code cell and press the play button to the left, or Ctrl-Enter, to execute it. An asterisc will be shown to the left of the cell when it is running. When finished it will show a sequenced number. If the code generates any output it will be shown below the code cell. Output can be anything from text and error reports to images, movies, and other media.\n",
    "\n",
    "## Enable GPU support\n",
    "\n",
    "Training a neural network involves heavy matrix computation. Using a GPU for this will speed up the process compared to using a regular CPU. On Kaggle you have 30 hours free GPU access per month. This is how you enable it:\n",
    "\n",
    "* Find *Settings* in the sidebar.\n",
    "* Select GPU as *Accelerator*. (Requires phone verification by SMS.)\n",
    "* Wait for Kaggle to reconfigure and restart your session.\n",
    "\n",
    "## Train your DCGAN\n",
    "\n",
    "Completing this part of the challange is as easy as to run all code cells one by one. You can stop execution at any time by clicking *Cancel run* in the upper toolbar. If you get errors complaining about full disc space, you can start fresh by restarting the session by clicking the rotating arrows button in the toolbar. Don't be afraid to changing hyperparameters or tweaking the code to try and improve your results. You can always start anew by saving a new copy of the project template if you end up with lots of errors and can't find your way back to a working application.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Application setup\n",
    "\n",
    "To make this notebook easier to read, most code has been put in a module called *dcgan*, that we import to the project. Implementation details has been abstracted away since they are beyond the scope of this challenge. But if you know a little Python you are more than welcome to take a look at the code to see what's going on under the hood. The implementation is far from optimal and you are more than welcome to improve it.\n",
    "\n",
    "We also define a file path to where our image data is. You can find this folder in the sidebar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plot\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, BatchNormalization, ReLU, LeakyReLU, Dropout, UpSampling2D, Activation\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "# Default values\n",
    "IMAGE_WIDTH = 64\n",
    "IMAGE_HEIGHT = 64\n",
    "IMAGE_CHANNELS = 3\n",
    "LEAKY_RELU_SLOPE = 0.2\n",
    "DROPOUT_RATE = 0.5\n",
    "WEIGHT_INIT_STD = 0.02\n",
    "WEIGHT_INIT_MEAN = 0.0\n",
    "LEARNING_RATE_INITIAL_D = 0.0002\n",
    "LEARNING_RATE_INITIAL_G = 0.0002\n",
    "NOISE_ARRAY_DIMENSION = 128\n",
    "BATCH_SIZE = 16\n",
    "LABEL_SMOOTHING = True\n",
    "LABEL_NOISE = True\n",
    "\n",
    "# TODO: try if loss_type is possible, refactor or remove.\n",
    "# TODO: expose more hyperparams\n",
    "\n",
    "class DCGAN():\n",
    "\n",
    "    def __init__(self, hyperparameters):\n",
    "        self.cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "        self.hyperparms = {\n",
    "            \"leaky_relu_slope\": LEAKY_RELU_SLOPE,\n",
    "            \"dropout_rate\": DROPOUT_RATE,\n",
    "            \"weight_init_std\": WEIGHT_INIT_STD,\n",
    "            \"weight_init_mean\": WEIGHT_INIT_MEAN,\n",
    "            \"learning_rate_initial_discriminator\": LEARNING_RATE_INITIAL_D,\n",
    "            \"learning_rate_initial_generator\": LEARNING_RATE_INITIAL_G,\n",
    "            \"noise_array_dimensions\": NOISE_ARRAY_DIMENSION,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"label_smoothing\": LABEL_SMOOTHING,\n",
    "            \"label_noise\": LABEL_NOISE\n",
    "        }\n",
    "        self.hyperparms.update(hyperparameters)\n",
    "\n",
    "    def train(self, dataset, generator, discriminator, output_dir=\".\", epochs=50, save_every_x_results=40):\n",
    "        noise_dim = self.hyperparms[\"noise_array_dimensions\"]\n",
    "        batch_size = self.hyperparms[\"batch_size\"]\n",
    "        lr_initial_g = self.hyperparms[\"learning_rate_initial_generator\"]\n",
    "        lr_initial_d = self.hyperparms[\"learning_rate_initial_discriminator\"]\n",
    "\n",
    "        # reused seed for plotting comparable images\n",
    "        num_examples_to_generate = 5\n",
    "        seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "\n",
    "        generator_optimizer = tf.keras.optimizers.Adam(learning_rate=tf.Variable(lr_initial_g), beta_1=0.5)\n",
    "        discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=tf.Variable(lr_initial_d), beta_1=0.5)\n",
    "\n",
    "        checkpoint_prefix = os.path.join(output_dir, \"ckpt\")\n",
    "        checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                         discriminator_optimizer=discriminator_optimizer,\n",
    "                                         generator=generator,\n",
    "                                         discriminator=discriminator)\n",
    "\n",
    "        all_g_loss = np.array([])\n",
    "        all_d_loss = np.array([])\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            epoch_g_loss = []\n",
    "            epoch_d_loss = []\n",
    "\n",
    "            start = time.time()\n",
    "            global_step = 0\n",
    "\n",
    "            for image_batch in dataset:\n",
    "                g_loss, d_loss = self.train_step(\n",
    "                    generator,\n",
    "                    generator_optimizer,\n",
    "                    discriminator,\n",
    "                    discriminator_optimizer,\n",
    "                    image_batch,\n",
    "                    batch_size,\n",
    "                    noise_dim)\n",
    "\n",
    "                global_step = global_step + 1\n",
    "                epoch_g_loss.append(g_loss)\n",
    "                epoch_d_loss.append(d_loss)\n",
    "                all_g_loss = np.append(all_g_loss, np.array([epoch_g_loss]))\n",
    "                all_d_loss = np.append(all_d_loss, np.array([epoch_d_loss]))\n",
    "\n",
    "            if (epoch + 1) % save_every_x_results == 0 or epoch == 0:\n",
    "                DCGAN.plot_losses(epoch_g_loss, epoch_d_loss, all_g_loss, all_d_loss, epoch + 1)\n",
    "                DCGAN.generate_and_save_images(generator, epoch + 1, seed, output_dir)\n",
    "                checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "            print(\"Epoch: {} computed for {} sec\".format(epoch + 1, time.time() - start))\n",
    "            print(\"Generator loss mean: \", np.mean(epoch_g_loss),\" std: \", np.std(epoch_g_loss))\n",
    "            print(\"Discriminator loss mean: \", np.mean(epoch_d_loss),\" std: \", np.std(epoch_d_loss))\n",
    "\n",
    "        DCGAN.generate_and_save_images(generator, epochs, seed, output_dir)\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "        print(\"Training completed.\")\n",
    "\n",
    "    def train_step(\n",
    "            self,\n",
    "            generator,\n",
    "            generator_optimizer,\n",
    "            discriminator,\n",
    "            discriminator_optimizer,\n",
    "            real_images, \n",
    "            batch_size, \n",
    "            noise_dim,\n",
    "            loss_type=\"gan\"):\n",
    "        label_smoothing = self.hyperparms[\"label_smoothing\"]\n",
    "        label_noise = self.hyperparms[\"label_noise\"]\n",
    "\n",
    "        noise = tf.random.normal([batch_size, noise_dim])\n",
    "\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            generated_images = generator(noise, training=True)\n",
    "\n",
    "            real_output = discriminator(real_images, training=True)\n",
    "            fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "            gen_loss = self.generator_loss(\n",
    "                real_output,\n",
    "                fake_output,\n",
    "                loss_type,\n",
    "                apply_label_smoothing=label_smoothing)\n",
    "\n",
    "            disc_loss = self.discriminator_loss(\n",
    "                real_output,\n",
    "                fake_output,\n",
    "                loss_type,\n",
    "                apply_label_smoothing=label_smoothing,\n",
    "                label_noise=label_noise)\n",
    "\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "        generator_optimizer.apply_gradients(\n",
    "            zip(gradients_of_generator, generator.trainable_variables))\n",
    "        discriminator_optimizer.apply_gradients(\n",
    "            zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "        return gen_loss, disc_loss\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_losses(epoch_g_loss, epoch_d_loss, all_g_loss, all_d_loss, epoch):\n",
    "        plot.figure(figsize=(10, 5))\n",
    "        plot.title(\"Epoch loss - EPOCH {}\".format(epoch))\n",
    "        plot.plot(epoch_g_loss, label=\"Generator\")\n",
    "        plot.plot(epoch_d_loss, label=\"Discriminator\")\n",
    "        plot.xlabel(\"Iterations\")\n",
    "        plot.ylabel(\"Loss\")\n",
    "        plot.legend()\n",
    "        plot.show()\n",
    "\n",
    "        plot.figure(figsize=(10, 5))\n",
    "        plot.plot(np.arange(len(all_g_loss)), all_g_loss, label=\"Generator\")\n",
    "        plot.plot(np.arange(len(all_d_loss)), all_d_loss, label=\"Discriminator\")\n",
    "        plot.legend()\n",
    "        plot.title(\"All epochs loss\")\n",
    "        plot.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_and_save_images(model, epoch, seed, output_dir):\n",
    "        # Training is set to false to run in inference mode.\n",
    "        predictions = model(seed, training=False)\n",
    "        predictions_count = predictions.shape[0]\n",
    "\n",
    "        for i in range(predictions_count):\n",
    "            plot.figure(figsize=(3, 3))\n",
    "            plot.imshow((predictions[i, :, :, :] * 127.5 + 127.5) / 255.)\n",
    "            plot.axis(\"off\")\n",
    "            plot.savefig(output_dir + \"/image-{}-at-epoch-{:05d}.png\".format(i, epoch))\n",
    "            plot.show()\n",
    "\n",
    "    # Label smoothing -- technique from GAN hacks, instead of assigning\n",
    "    # 1/0 as class labels, we assign a random integer in range [0.7, 1.0]\n",
    "    # for positive class and [0.0, 0.3] for negative class.\n",
    "    @staticmethod\n",
    "    def smooth_positive_labels(y):\n",
    "        rng = np.random.default_rng()\n",
    "        return y - 0.3 * rng.random(y.shape)\n",
    "\n",
    "    @staticmethod\n",
    "    def smooth_negative_labels(y):\n",
    "        rng = np.random.default_rng()\n",
    "        return y + rng.random(y.shape) * 0.3\n",
    "\n",
    "    # Instance noise -- randomly flip some labels\n",
    "    @staticmethod\n",
    "    def noisy_labels(y, p_flip):\n",
    "        # determine the number of labels to flip\n",
    "        n_select = int(p_flip * int(y.shape[0]))\n",
    "        # choose labels to flip\n",
    "        flip_ix = np.random.choice([i for i in range(int(y.shape[0]))], size=n_select)\n",
    "\n",
    "        op_list = []\n",
    "        # invert the labels in place\n",
    "        #y_np[flip_ix] = 1 - y_np[flip_ix]\n",
    "        for i in range(int(y.shape[0])):\n",
    "            if i in flip_ix:\n",
    "                op_list.append(tf.subtract(1, y[i]))\n",
    "            else:\n",
    "                op_list.append(y[i])\n",
    "\n",
    "        outputs = tf.stack(op_list)\n",
    "        return outputs\n",
    "\n",
    "    def discriminator_loss(self, real_output, fake_output, loss_func, apply_label_smoothing=True, label_noise=True):\n",
    "        real_labels = tf.ones_like(real_output)\n",
    "        fake_labels = tf.zeros_like(fake_output)\n",
    "\n",
    "        if label_noise:\n",
    "            real_labels = DCGAN.noisy_labels(real_labels, 0.05)\n",
    "            fake_labels = DCGAN.noisy_labels(fake_labels, 0.05)\n",
    "\n",
    "        if apply_label_smoothing:\n",
    "            real_labels = DCGAN.smooth_positive_labels(real_labels)\n",
    "            fake_labels = DCGAN.smooth_negative_labels(fake_labels)\n",
    "\n",
    "            # if loss_func == 'gan':\n",
    "        real_loss = self.cross_entropy(real_labels, real_output)\n",
    "        fake_loss = self.cross_entropy(fake_labels, fake_output)\n",
    "\n",
    "        total_loss = real_loss + fake_loss\n",
    "        return total_loss\n",
    "\n",
    "        #     else:\n",
    "        #         if loss_func == 'ralsgan':\n",
    "        #             return (tf.reduce_mean(tf.math.square(real_output_smooth - tf.math.reduce_mean(fake_output_smooth) - tf.ones_like(real_output_smooth)))\n",
    "        #     + tf.math.reduce_mean(tf.math.square(fake_output_smooth - tf.math.reduce_mean(real_output_smooth) + tf.ones_like(fake_output_smooth)))) / 2.\n",
    "        #         elif loss_func == 'rasgan':\n",
    "        #             avg_fake_logit = tf.math.reduce_mean(fake_output_smooth)\n",
    "        #             avg_real_logit = tf.math.reduce_mean(real_output_smooth)\n",
    "        #             D_r_tilde = tf.nn.sigmoid(real_output_smooth - avg_fake_logit)\n",
    "        #             D_f_tilde = tf.nn.sigmoid(fake_output_smooth - avg_real_logit)\n",
    "        #             total_loss = - tf.math.reduce_mean(tf.math.log(\n",
    "        #                 D_r_tilde + 1e-14)) - tf.math.reduce_mean(tf.math.log(1 - D_f_tilde + 1e-14))\n",
    "        #             return total_loss\n",
    "        #         elif loss_func == 'rahinge':\n",
    "        #             real_loss = tf.math.reduce_mean(tf.nn.relu(tf.ones_like(real_output_smooth) - (real_output_smooth - tf.math.reduce_mean(fake_output_smooth))))\n",
    "        #             fake_loss = tf.math.reduce_mean(tf.nn.relu(tf.ones_like(fake_output_smooth) + (fake_output_smooth - tf.math.reduce_mean(real_output_smooth))))\n",
    "            # total_loss = real_loss + fake_loss\n",
    "            # return total_loss\n",
    "\n",
    "    def generator_loss(self, real_output, fake_output, loss_func, apply_label_smoothing=True):\n",
    "        fake_labels = tf.ones_like(fake_output)\n",
    "        if apply_label_smoothing:\n",
    "            fake_labels = DCGAN.smooth_positive_labels(fake_labels)\n",
    "\n",
    "            # if loss_func == 'gan':\n",
    "        return self.cross_entropy(fake_labels, fake_output)\n",
    "        #     else:\n",
    "        #         if loss_func == 'ralsgan':\n",
    "        #             return (tf.reduce_mean(tf.square(real_output - tf.reduce_mean(fake_output_smooth) + tf.ones_like(real_output)))\n",
    "        #     + tf.reduce_mean(tf.square(fake_output_smooth - tf.reduce_mean(real_output) - tf.ones_like(fake_output_smooth)))) / 2.\n",
    "        #         elif loss_func == 'rasgan':\n",
    "        #             avg_fake_logit = tf.reduce_mean(fake_output_smooth)\n",
    "        #             avg_real_logit = tf.reduce_mean(real_output)\n",
    "        #             D_r_tilde = tf.nn.sigmoid(real_output - avg_fake_logit)\n",
    "        #             D_f_tilde = tf.nn.sigmoid(fake_output_smooth - avg_real_logit)\n",
    "        #             total_loss = - tf.reduce_mean(tf.log(\n",
    "        #                 D_f_tilde + 1e-14)) - tf.reduce_mean(tf.log(1 - D_r_tilde + 1e-14))\n",
    "        #             return total_loss\n",
    "        #         elif loss_func == 'rahinge':\n",
    "        #             fake_loss = tf.reduce_mean(tf.nn.relu(tf.ones_like(fake_output_smooth) - (fake_output_smooth - tf.reduce_mean(real_output))))\n",
    "        #             real_loss = tf.reduce_mean(tf.nn.relu(tf.ones_like(real_output) + (real_output - tf.reduce_mean(fake_output_smooth))))\n",
    "        #             loss = fake_loss + real_loss\n",
    "        #             return loss\n",
    "\n",
    "    def upsampling(self, model, filters, kernel_size=(5, 5), strides=(1, 1)):\n",
    "        model.add(UpSampling2D(size=(2, 2)))\n",
    "        model.add(Conv2D(filters, kernel_size, strides=strides, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        return model\n",
    "\n",
    "    def weight_initializer(self):\n",
    "        weight_init_std = self.hyperparms[\"weight_init_std\"]\n",
    "        weight_init_mean = self.hyperparms[\"weight_init_mean\"]\n",
    "        return TruncatedNormal(stddev=weight_init_std, mean=weight_init_mean, seed=42)\n",
    "\n",
    "    def transposed_conv(self, model, out_channels, ksize, stride_size, padding_type=\"same\"):\n",
    "        initializer = self.weight_initializer()\n",
    "        model.add(Conv2DTranspose(\n",
    "            out_channels,\n",
    "            (ksize, ksize),\n",
    "            strides=(stride_size, stride_size),\n",
    "            padding=padding_type, \n",
    "            kernel_initializer=initializer,\n",
    "            use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "        return model\n",
    "\n",
    "    def conv(self, model, out_channels, ksize, stride_size, leaky_relu_slope, padding_type=\"same\"):\n",
    "        initializer = self.weight_initializer()\n",
    "        model.add(Conv2D(\n",
    "            out_channels, \n",
    "            (ksize, ksize), \n",
    "            strides=(stride_size, stride_size), \n",
    "            padding=padding_type,\n",
    "            kernel_initializer=initializer))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=leaky_relu_slope))\n",
    "        return model\n",
    "\n",
    "    def build_generator(self):\n",
    "        initializer = self.weight_initializer()\n",
    "        noise_dim = self.hyperparms[\"noise_array_dimensions\"]\n",
    "        dropout_rate = self.hyperparms[\"dropout_rate\"]\n",
    "\n",
    "        # noise_dim * 1 (noise)     project and reshape\n",
    "        # 4 * 4 * 1024              conv 1\n",
    "        # 8 * 8 * 512               conv 2\n",
    "        # 16 * 16 * 256             conv 3\n",
    "        # 32 * 32 * 128             conv 4\n",
    "        # 64 * 64 * 3\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(4 * 4 * 1024, input_shape=(noise_dim,), kernel_initializer=initializer))\n",
    "        model.add(Reshape((4, 4, 1024)))\n",
    "\n",
    "        model = self.upsampling(model, 256, (5, 5))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model = self.upsampling(model, 128, (5, 5))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model = self.upsampling(model, 64, (3, 3))\n",
    "        model = self.upsampling(model, 32, (3, 3))\n",
    "\n",
    "        model.add(Dense(IMAGE_CHANNELS, activation=\"tanh\", kernel_initializer=initializer))\n",
    "        return model\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        leaky_relu_slope = self.hyperparms[\"leaky_relu_slope\"]\n",
    "        initializer = self.weight_initializer()\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(\n",
    "            64,\n",
    "            (4, 4),\n",
    "            strides=(1, 1),\n",
    "            padding=\"same\",\n",
    "            use_bias=False,\n",
    "            input_shape=[IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS],\n",
    "            kernel_initializer=initializer))\n",
    "        model.add(LeakyReLU(alpha=leaky_relu_slope))\n",
    "\n",
    "        model = self.conv(model, 64, 4, 2, leaky_relu_slope)\n",
    "        model = self.conv(model, 128, 4, 2, leaky_relu_slope)\n",
    "        model = self.conv(model, 256, 4, 2, leaky_relu_slope)\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation=\"sigmoid\"))\n",
    "        return model\n",
    "\n",
    "    def create_dataset(self, image_dir):\n",
    "        image_height = IMAGE_HEIGHT\n",
    "        image_width = IMAGE_WIDTH\n",
    "        image_channels = IMAGE_CHANNELS\n",
    "        batch_size = self.hyperparms[\"batch_size\"]\n",
    "\n",
    "        image_list = os.listdir(image_dir)\n",
    "        image_count = len(image_list)\n",
    "\n",
    "        training_data = np.empty((image_count, image_height, image_width, image_channels))\n",
    "\n",
    "        plot.figure(figsize=(10, 10))\n",
    "\n",
    "        index = 0\n",
    "        for filename in image_list:\n",
    "            path = os.path.join(image_dir, filename)\n",
    "            original = Image.open(path)\n",
    "\n",
    "            image = original.resize((image_width, image_height), Image.BICUBIC)\n",
    "            training_data[index,:,:,:] = np.asarray(image)\n",
    "            index += 1\n",
    "\n",
    "            if index <= 30:\n",
    "                plot.xticks([])\n",
    "                plot.yticks([])\n",
    "                plot.grid(False)\n",
    "                plot.subplot(5, 6, index)\n",
    "                plot.imshow(image)\n",
    "\n",
    "        plot.show()\n",
    "\n",
    "        # normalize pixel value range to [-1, 1]\n",
    "        training_data = (training_data - 127.5) / 127.5\n",
    "\n",
    "        tensor = tf.cast(training_data, \"float32\")\n",
    "\n",
    "        return tf.data.Dataset.from_tensor_slices(tensor).shuffle(10000).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "IMAGE_DIR = \"../input/segmented-bob-ross-images/train/images\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define hyperparameters\n",
    "\n",
    "In machine learning we separate parameters from hyperparameters. Hyperparameters are all parameters that are set before starting the training process. The other parameters or weights are learnt automatically in the training process. Different settings of the hyperparameters can make a huge effect on the outcome of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"leaky_relu_slope\": 0.0,\n",
    "    \"dropout_rate\": 0.0,\n",
    "    \"weight_init_std\": 0.5,\n",
    "    \"weight_init_mean\": 0.0,\n",
    "    \"learning_rate_initial_discriminator\": 0.0,\n",
    "    \"learning_rate_initial_generator\": 0.0,\n",
    "    \"noise_array_dimensions\": 50,\n",
    "    \"batch_size\": 16,\n",
    "    \"label_smoothing\": False,\n",
    "    \"label_noise\": False\n",
    "}\n",
    "dcgan = DCGAN(hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create training dataset\n",
    "\n",
    "The images in the input folder are preprocessed and stored in a binary format that the training algorithm can work efficiently with. Each image is also downsampled to 64 by 64 pixels to reduce the training time. This code cell should output a few example images from the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dcgan.create_dataset(IMAGE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generator and Discriminator\n",
    "\n",
    "The DCGAN architecture is basically two neural networks competing against each other in the training process. The discriminator takes an image as input and is trained to predict if the image is real or fake. Real in this case means being part of the dataset we trained the model on. The generator takes some noise as input and is trained to fool the discriminator by generating images that resemble the images of the training dataset to a level that the discriminator can not tell them apart from real images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = dcgan.build_generator()\n",
    "discriminator = dcgan.build_discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. The training process\n",
    "\n",
    "To start training we pass the dataset, generator and discriminator to the *train* function. We also specify how many epochs we want the process to repeat, and we tell it to plot and display generated images for every x epoch. Doing this at every iteration would soon fill the disc space we are allowed to use on Kaggle.\n",
    "\n",
    "When training starts both networks are equally bad. The discriminator predictions will be random and the generator will produce random noise images. As the training goes on both networks should become better at their tasks because the results are fed back in the training loop and progress in the generator should trigger progress in the discriminator and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan.train(\n",
    "    dataset,\n",
    "    generator, \n",
    "    discriminator,\n",
    "    epochs=5000,\n",
    "    save_every_x_results=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Evaluating trainging progress\n",
    "\n",
    "As you can see in the output above, each training epoch runs for a few seconds (at least for the initial configuration). For each epoch a *loss* value is computed for both the generator and discriminator. This value is a measure of how far off from the truth the network is when making a prediction. A lower value means the prediction is better. The loss value is what is fed back from one iteration to the next to enable learning of the neural network weights. The loss value is fed into an *optimizer* function that calculates how the weights should be adjusted for the network to improve. How the optimizer works is beyond the scope of this excercise. The loss values are easier to reason about here. If you are able to run a successfull training session for long enough, you will see in the *All epochs loss* graph how the loss values go up and down all the time but starts stabilizing at different levels after some number of iterations. When training for example an image object detection network for detecting different animals, you will see the loss value decrease to a more stable low number, with less variance. But when training a GAN the loss values will keep fluctuating. This is because the generator and discriminator keep competing and influencing each others loss function.\n",
    "\n",
    "How do you know training is complete? You don't! You'll have to watch the output and decide when you think the results stop improving. You should also interupt training if the DCGAN doesn't seem to learn anything and the generator keeps generating random noise images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Try different hyperparameters\n",
    "\n",
    "Now go back to the code cell where we defined hyperparameters. Change some values, run all code cells again, and see if you can improve the results. There are plenty articles on the web that can guide you to hyperparameter settings for stable training of a DCGAN. If you know Python programming you can make a copy of the dcgan utility script and see if you can do any changes to the code to improve your results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
